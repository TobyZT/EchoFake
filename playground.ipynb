{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de215670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from datasets import load_dataset, Audio, ClassLabel\n",
    "\n",
    "# class_label = ClassLabel(names=[\"bonafide\", \"replay_bonafide\", \"fake\", \"replay_fake\"])\n",
    "\n",
    "ds = load_dataset(\n",
    "    \"json\",\n",
    "    data_files={\n",
    "        \"train\": \"/data1/zt/ReplayDeepfake/data/train.jsonl\",\n",
    "        \"dev\": \"/data1/zt/ReplayDeepfake/data/dev.jsonl\",\n",
    "        \"closed_set_eval\": \"/data1/zt/ReplayDeepfake/data/eval.jsonl\",\n",
    "    },\n",
    ")\n",
    "ds = ds.cast_column(\"path\", Audio())\n",
    "# ds = ds.cast_column(\"label\", class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e76d58ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1735982c19c4db898e19c7049fc10f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/4 shards):   0%|          | 0/39926 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98f9c9b380f647d7bbba289e8c41e6e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/3973 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b478feefec5e472cb010fec762561227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5991 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds.save_to_disk(\"EchoFake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "295f5bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "ds = load_from_disk(\"EchoFake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3225005c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'utt_id': 'EF_T_39877', 'path': {'path': 'EF_T_39877.mp3', 'array': array([-7.05333587e-05,  3.73185685e-06,  6.12027070e-05, ...,\n",
      "       -7.26406652e-05,  2.31373560e-04,  2.09870588e-04], shape=(117419,)), 'sampling_rate': 16000}, 'label': 3, 'source': 'common_voice_en_27450201.mp3', 'source_text': 'He was invited to the Konigswinter conferences by Lilo Milchsack.', 'source_speaker_id': 'e31822077e104d2f1781db7ce098c016abca0314515a35f564b26c30e59c0d2a0206cdf020dfbfe4e7340388f898c34d51e2d625681694a797c49581af656fba', 'replay_details': {'room_size': '4.8m(L) * 3.2m(W) * 3.2m(H)', 'player': 'iPad Mini (7th generation)', 'recorder': 'iPhone 13 mini', 'distance': '15cm'}, 'synthesis_details': {'model': 'LLaSA', 'reference': 'common_voice_en_27450201.mp3', 'reference_text': \"Now, everything's done on synthesizers.\", 'reference_speaker_id': 'b87dd0680063cbd3dc57f5b9b20c14f020f511c3f18467d52e816db909dbe2be05b8ea36a4bca91179503817a1b093a9e6036abb514c6ad1aaf1ffa71b3d32ce'}}\n",
      "['utt_id', 'path', 'label', 'source', 'source_text', 'source_speaker_id', 'replay_details', 'synthesis_details']\n",
      "ClassLabel(names=['bonafide', 'replay_bonafide', 'fake', 'replay_fake'], id=None)\n"
     ]
    }
   ],
   "source": [
    "print(ds[\"train\"][39876])\n",
    "print(ds[\"train\"].column_names)\n",
    "print(ds[\"train\"].features[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce59414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def pad(x, max_len=64000):\n",
    "    x_len = x.shape[0]\n",
    "    if x_len >= max_len:\n",
    "        return x[:max_len]\n",
    "    # need to pad\n",
    "    num_repeats = int(max_len / x_len) + 1\n",
    "    padded_x = np.tile(x, (1, num_repeats))[:, :max_len][0]\n",
    "    return padded_x\n",
    "\n",
    "\n",
    "def pad_random(x: np.ndarray, max_len: int = 64000):\n",
    "    x_len = x.shape[0]\n",
    "    if x_len == max_len:\n",
    "        return x\n",
    "\n",
    "    # if duration is already long enough\n",
    "    if x_len >= max_len:\n",
    "        stt = np.random.randint(x_len - max_len)\n",
    "        return x[stt : stt + max_len]\n",
    "\n",
    "    # if too short\n",
    "    num_repeats = int(max_len / x_len) + 1\n",
    "    padded_x = np.tile(x, num_repeats)[:max_len]\n",
    "    return padded_x\n",
    "\n",
    "\n",
    "def preprocess(batch):\n",
    "    wav = batch[\"path\"][\"array\"]  # np.ndarray [T]\n",
    "    wav = pad_random(wav, max_len=64000).astype(np.float32)\n",
    "    return {\"input_values\": wav, \"labels\": batch[\"label\"]}\n",
    "\n",
    "\n",
    "def preprocess_for_test(batch):\n",
    "    wav = batch[\"path\"][\"array\"]  # np.ndarray [T]\n",
    "    wav = pad(wav, max_len=64000).astype(np.float32)\n",
    "    return {\"input_values\": wav, \"labels\": batch[\"label\"]}\n",
    "\n",
    "\n",
    "unused_columns = [\n",
    "    \"source\",\n",
    "    \"source_text\",\n",
    "    \"source_speaker_id\",\n",
    "    \"replay_details\",\n",
    "    \"synthesis_details\",\n",
    "]\n",
    "trainset = ds[\"train\"].map(preprocess, remove_columns=unused_columns)\n",
    "devset = ds[\"dev\"].map(preprocess, remove_columns=unused_columns)\n",
    "evalset = ds[\"closed_set_eval\"].map(preprocess_for_test, remove_columns=unused_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab90711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from models import RawNet2\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Step 3: 模型\n",
    "model = RawNet2(device=device).to(device)\n",
    "\n",
    "# Step 4: 训练参数\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./checkpoints\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "\n",
    "# Step 5: 评价函数\n",
    "def compute_metrics(pred):\n",
    "    logits = pred.predictions\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds),\n",
    "        \"auc\": roc_auc_score(labels, logits[:, 1]),\n",
    "    }\n",
    "\n",
    "\n",
    "# Step 6: Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Step 7: 训练\n",
    "trainer.train()\n",
    "\n",
    "# Step 8: 保存模型\n",
    "model.save_pretrained(\"rawnet2_fakedetection\")\n",
    "torch.save(model.state_dict(), \"rawnet2_fakedetection/pytorch_model.bin\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
