{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de215670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "import torch\n",
    "import torchaudio\n",
    "import librosa\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_from_disk\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab049782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13100\n",
      "['/data1/datasets/wavefake/wavs16/LJ015-0284.wav', '/data1/datasets/wavefake/wavs16/LJ020-0055.wav', '/data1/datasets/wavefake/wavs16/LJ004-0165.wav', '/data1/datasets/wavefake/wavs16/LJ019-0335.wav', '/data1/datasets/wavefake/wavs16/LJ050-0235.wav', '/data1/datasets/wavefake/wavs16/LJ009-0201.wav', '/data1/datasets/wavefake/wavs16/LJ013-0206.wav', '/data1/datasets/wavefake/wavs16/LJ031-0042.wav', '/data1/datasets/wavefake/wavs16/LJ048-0170.wav', '/data1/datasets/wavefake/wavs16/LJ043-0034.wav']\n",
      "117983\n",
      "['/data1/datasets/wavefake/generated_audio/common_voices_prompts_from_conformer_fastspeech2_pwg_ljspeech/gen_6128.wav', '/data1/datasets/wavefake/generated_audio/common_voices_prompts_from_conformer_fastspeech2_pwg_ljspeech/gen_13352.wav', '/data1/datasets/wavefake/generated_audio/common_voices_prompts_from_conformer_fastspeech2_pwg_ljspeech/gen_10907.wav', '/data1/datasets/wavefake/generated_audio/common_voices_prompts_from_conformer_fastspeech2_pwg_ljspeech/gen_1266.wav', '/data1/datasets/wavefake/generated_audio/common_voices_prompts_from_conformer_fastspeech2_pwg_ljspeech/gen_10440.wav', '/data1/datasets/wavefake/generated_audio/common_voices_prompts_from_conformer_fastspeech2_pwg_ljspeech/gen_2257.wav', '/data1/datasets/wavefake/generated_audio/common_voices_prompts_from_conformer_fastspeech2_pwg_ljspeech/gen_6184.wav', '/data1/datasets/wavefake/generated_audio/common_voices_prompts_from_conformer_fastspeech2_pwg_ljspeech/gen_2520.wav', '/data1/datasets/wavefake/generated_audio/common_voices_prompts_from_conformer_fastspeech2_pwg_ljspeech/gen_13871.wav', '/data1/datasets/wavefake/generated_audio/common_voices_prompts_from_conformer_fastspeech2_pwg_ljspeech/gen_1617.wav']\n"
     ]
    }
   ],
   "source": [
    "base_dir = Path(\"/data1/datasets/wavefake/\")\n",
    "bonafide_list = glob.glob(str(base_dir / \"wavs16\" / \"*.wav\"))\n",
    "print(len(bonafide_list))\n",
    "print(bonafide_list[:10])\n",
    "\n",
    "fake_list = glob.glob(str(base_dir / \"generated_audio\" / \"*\" / \"*.wav\"))\n",
    "print(len(fake_list))\n",
    "print(fake_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb24a2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/data1/datasets/wavefake/\"\n",
    "\n",
    "\n",
    "class WaveFakeDataset(Dataset):\n",
    "    def __init__(self, base_dir, pad_mode=\"random\", max_len=64000):\n",
    "        \"\"\"\n",
    "        In-the-Wild datamodule for evaluation\n",
    "        \"\"\"\n",
    "        self.base_dir = base_dir\n",
    "        self.wav_paths = []\n",
    "        self.labels = []\n",
    "        if pad_mode == \"random\":\n",
    "            self.pad = pad_random\n",
    "        else:\n",
    "            self.pad = pad\n",
    "        self.max_len = max_len\n",
    "        self.parse_protocol()\n",
    "\n",
    "    def parse_protocol(self):\n",
    "        bonafide_list = glob.glob(str(self.base_dir / \"wavs16\" / \"*.wav\"))\n",
    "        fake_list = glob.glob(str(self.base_dir / \"generated_audio\" / \"*\" / \"*.wav\"))\n",
    "        for path in bonafide_list:\n",
    "            self.wav_paths.append(path)\n",
    "            self.labels.append(1)\n",
    "        for path in fake_list:\n",
    "            self.wav_paths.append(path)\n",
    "            self.labels.append(0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.wav_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.wav_paths[index]\n",
    "        x, _ = librosa.load(path, sr=16000)\n",
    "        x = torch.Tensor(self.pad(x, self.max_len))\n",
    "        y = torch.LongTensor([1]) if self.labels[index] == 1 else torch.LongTensor([0])\n",
    "        y = y.squeeze()\n",
    "        return x, y\n",
    "\n",
    "\n",
    "class WaveFake(L.LightningDataModule):\n",
    "    def __init__(self, base_dir, max_len=64000, **dataloaderArgs):\n",
    "        super().__init__()\n",
    "        self.base_dir = Path(base_dir)\n",
    "        self.max_len = max_len\n",
    "        self.dataloaderArgs = dataloaderArgs\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        self.trainset = WaveFakeDataset(\n",
    "            self.base_dir, pad_mode=\"random\", max_len=self.max_len\n",
    "        )\n",
    "        self.valset = WaveFakeDataset(\n",
    "            self.base_dir, pad_mode=\"random\", max_len=self.max_len\n",
    "        )\n",
    "        self.testset = WaveFakeDataset(\n",
    "            self.base_dir, pad_mode=\"normal\", max_len=self.max_len\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.trainset, shuffle=True, **self.dataloaderArgs)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.valset, shuffle=False, **self.dataloaderArgs)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.testset, shuffle=False, **self.dataloaderArgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd92c118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch x shape: torch.Size([16, 64000])\n",
      "Batch y shape: torch.Size([16])\n",
      "Batch y: tensor([1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# Test the WaveFake dataset and datamodule\n",
    "data_module = WaveFake(base_dir=base_dir, max_len=64000, batch_size=16, num_workers=2)\n",
    "data_module.setup(stage=\"fit\")\n",
    "\n",
    "# Fetch a batch from the train dataloader\n",
    "train_loader = data_module.train_dataloader()\n",
    "batch = next(iter(train_loader))\n",
    "x, y = batch\n",
    "\n",
    "print(\"Batch x shape:\", x.shape)\n",
    "print(\"Batch y shape:\", y.shape)\n",
    "print(\"Batch y:\", y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
